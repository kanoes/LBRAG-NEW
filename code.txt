<__init__.py>
from .metrics import cost_normalized_bridging_efficiency, response_language_consistency
from .pipeline import LBRAGPipeline, PipelineOutput, WeightingConfig
from .prompting import PromptBuilder, PromptTemplate
from .retrieval import HybridRetriever, RetrievalConfig
from .selection import TranslationCandidate, TranslationPlan, TranslationSelector
from .translation import SimpleSentenceSplitter, estimate_alignment_quality, greedy_sentence_alignment
from .types import (
    DocumentSegment,
    EvidenceBlock,
    Query,
    RetrievalCandidate,
    SentenceAlignment,
    TranslationRequest,
    TranslationResult,
)

__all__ = [
    "cost_normalized_bridging_efficiency",
    "response_language_consistency",
    "LBRAGPipeline",
    "PipelineOutput",
    "WeightingConfig",
    "PromptBuilder",
    "PromptTemplate",
    "HybridRetriever",
    "RetrievalConfig",
    "TranslationCandidate",
    "TranslationPlan",
    "TranslationSelector",
    "SimpleSentenceSplitter",
    "estimate_alignment_quality",
    "greedy_sentence_alignment",
    "DocumentSegment",
    "EvidenceBlock",
    "Query",
    "RetrievalCandidate",
    "SentenceAlignment",
    "TranslationRequest",
    "TranslationResult",
]

<integrations.py>
from __future__ import annotations

import os
import re
import json
from dataclasses import dataclass, field
from typing import Iterable, Optional, Sequence

import requests
from openai import OpenAI

from .retrieval import Reranker, Retriever
from .selection import ConfidenceEstimate, ConfidenceEstimator
from .translation import RegexSentenceSplitter, SentenceSplitter, SupportsBackTranslation, Translator
from .types import DocumentSegment, Query, RetrievalCandidate, TranslationRequest, TranslationResult


class OpenAIChatGenerator:
    def __init__(self, model: str = "gpt-4o-mini", api_key: Optional[str] = None, system_instruction: str | None = None) -> None:
        self._client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))
        self._model = model
        self._system = system_instruction or "You are a helpful multilingual assistant."

    def generate(self, prompt: str) -> str:
        response = self._client.chat.completions.create(
            model=self._model,
            messages=[
                {"role": "system", "content": self._system},
                {"role": "user", "content": prompt},
            ],
        )
        return (response.choices[0].message.content or "").strip()


@dataclass
class OpenAITranslator(Translator, SupportsBackTranslation):
    model: str = "gpt-4o-mini"
    api_key: Optional[str] = None
    splitter: SentenceSplitter = field(default_factory=RegexSentenceSplitter)

    def __post_init__(self) -> None:
        self._client = OpenAI(api_key=self.api_key or os.getenv("OPENAI_API_KEY"))

    def translate(self, request: TranslationRequest) -> TranslationResult:
        prompt = (
            "Translate the following passage to {lang} preserving numbers, dates, and names.\n\n"
            "Source ({source_lang}):\n{source}\n"
        ).format(lang=request.target_language, source_lang=request.segment.language, source=request.segment.text)
        response = self._client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "You translate precisely without omitting information."},
                {"role": "user", "content": prompt},
            ],
        )
        translated = (response.choices[0].message.content or "").strip()
        sentences = self.splitter.split(translated)
        metadata = {
            "token_count": self.estimate_cost(request),
        }
        return TranslationResult(
            translated_text=translated,
            confidence=1.0,
            sentences=sentences,
            metadata=metadata,
        )

    def estimate_cost(self, request: TranslationRequest) -> float:
        tokens = max(len(request.segment.text) // 3, 1)
        return float(tokens)

    def back_translate(self, text: str, source_language: str) -> str:
        response = self._client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "You translate precisely without omitting information."},
                {"role": "user", "content": f"Translate this passage to {source_language}:\n{text}"},
            ],
        )
        return (response.choices[0].message.content or "").strip()


@dataclass
class OpenAIEmbeddingRetriever(Retriever):
    documents: Sequence[DocumentSegment]
    embedding_model: str = "text-embedding-3-small"
    api_key: Optional[str] = None

    def __post_init__(self) -> None:
        self._client = OpenAI(api_key=self.api_key or os.getenv("OPENAI_API_KEY"))
        self._vectors = self._embed_documents(self.documents)

    def retrieve(self, query: Query, top_k: int) -> Sequence[RetrievalCandidate]:
        embedding = self._client.embeddings.create(model=self.embedding_model, input=query.text).data[0].embedding
        scored = []
        for vector, segment in zip(self._vectors, self.documents):
            score = self._dot(vector, embedding)
            scored.append(
                RetrievalCandidate(
                    segment=segment,
                    dense_score=score,
                    rerank_score=None,
                )
            )
        scored.sort(key=lambda c: c.dense_score, reverse=True)
        return tuple(scored[:top_k])

    def _embed_documents(self, documents: Sequence[DocumentSegment]) -> Sequence[Sequence[float]]:
        texts = [doc.text for doc in documents]
        response = self._client.embeddings.create(model=self.embedding_model, input=texts)
        return [item.embedding for item in response.data]

    @staticmethod
    def _dot(a: Sequence[float], b: Sequence[float]) -> float:
        return float(sum(x * y for x, y in zip(a, b)))


@dataclass
class TavilyRetriever(Retriever):
    api_key: Optional[str] = None
    include_domains: Sequence[str] | None = None

    def retrieve(self, query: Query, top_k: int) -> Sequence[RetrievalCandidate]:
        key = self.api_key or os.getenv("TAVILY_API_KEY")
        response = requests.post(
            "https://api.tavily.com/search",
            json={
                "api_key": key,
                "query": query.text,
                "search_depth": "advanced",
                "max_results": top_k,
                "include_domains": list(self.include_domains) if self.include_domains else None,
            },
            timeout=30,
        )
        response.raise_for_status()
        data = response.json()
        candidates = []
        for item in data.get("results", [])[:top_k]:
            identifier = item.get("url") or item.get("title")
            text = item.get("content") or ""
            segment = DocumentSegment(
                identifier=identifier,
                text=text,
                language=query.language,
                metadata={"source": item.get("url"), "title": item.get("title")},
            )
            candidates.append(
                RetrievalCandidate(
                    segment=segment,
                    dense_score=float(item.get("score", 0.0)),
                    rerank_score=None,
                )
            )
        return tuple(candidates)


@dataclass
class QdrantRetriever(Retriever):
    collection: str
    url: str = field(default_factory=lambda: os.getenv("QDRANT_URL", "http://localhost:6333"))
    api_key: Optional[str] = field(default_factory=lambda: os.getenv("QDRANT_API_KEY"))
    embedding_model: str = "text-embedding-3-small"
    api_key_openai: Optional[str] = None

    def __post_init__(self) -> None:
        self._openai = OpenAI(api_key=self.api_key_openai or os.getenv("OPENAI_API_KEY"))

    def retrieve(self, query: Query, top_k: int) -> Sequence[RetrievalCandidate]:
        embedding = self._openai.embeddings.create(model=self.embedding_model, input=query.text).data[0].embedding
        payload = {
            "vector": embedding,
            "limit": top_k,
            "with_payload": True,
        }
        headers = {"Content-Type": "application/json"}
        if self.api_key:
            headers["api-key"] = self.api_key
        response = requests.post(
            f"{self.url}/collections/{self.collection}/points/search",
            json=payload,
            headers=headers,
            timeout=30,
        )
        response.raise_for_status()
        points = response.json().get("result", [])
        candidates = []
        for point in points:
            payload = point.get("payload", {})
            identifier = str(point.get("id", payload.get("id")))
            text = payload.get("text") or payload.get("content", "")
            language = payload.get("language", query.language)
            segment = DocumentSegment(
                identifier=identifier,
                text=text,
                language=language,
                metadata=payload,
            )
            candidates.append(
                RetrievalCandidate(
                    segment=segment,
                    dense_score=float(point.get("score", 0.0)),
                    rerank_score=None,
                )
            )
        return tuple(candidates[:top_k])


@dataclass
class OpenAIListwiseReranker(Reranker):
    model: str = "gpt-4o-mini"
    api_key: Optional[str] = None

    def __post_init__(self) -> None:
        self._client = OpenAI(api_key=self.api_key or os.getenv("OPENAI_API_KEY"))

    def score(self, query: Query, candidates: Sequence[DocumentSegment]) -> Sequence[float]:
        if not candidates:
            return tuple()
        prompt = self._build_prompt(query, candidates)
        response = self._client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "Score relevance between 0 and 1."},
                {"role": "user", "content": prompt},
            ],
        )
        content = (response.choices[0].message.content or "").strip()
        scores = self._parse_scores(content, len(candidates))
        return tuple(scores)

    def _build_prompt(self, query: Query, candidates: Sequence[DocumentSegment]) -> str:
        lines = [f"Query ({query.language}): {query.text}", "\nCandidates:"]
        for idx, candidate in enumerate(candidates, start=1):
            lines.append(f"[{idx}] ({candidate.language}) {candidate.text}")
        lines.append("\nProvide scores as JSON array of floats in candidate order.")
        return "\n".join(lines)

    @staticmethod
    def _parse_scores(content: str, expected: int) -> Sequence[float]:
        try:
            m = re.search(r"\[[^\]]+\]", content, flags=re.S)
            if m:
                arr = json.loads(m.group(0))
                if isinstance(arr, list) and len(arr) >= expected:
                    return [float(arr[i]) for i in range(expected)]
        except Exception:
            pass
        nums = re.findall(r"(?:^|\s)(0(?:\.\d+)?|1(?:\.0+)?)", content)
        if len(nums) >= expected:
            return [float(nums[i]) for i in range(expected)]
        return [0.0] * expected


@dataclass
class StaticConfidenceEstimator(ConfidenceEstimator):
    confidence: float = 1.0

    def estimate(self, segment: DocumentSegment, target_language: str) -> ConfidenceEstimate:
        return ConfidenceEstimate(
            value=self.confidence,
            details={"static": self.confidence},
            preview=None,
        )

<metrics.py>
from __future__ import annotations

from typing import Iterable, Sequence


def response_language_consistency(tokens: Sequence[str], allowed_tokens: Iterable[str]) -> float:
    allowed = set(allowed_tokens)
    if not tokens:
        return 0.0
    hits = sum(1 for token in tokens if token in allowed)
    return hits / len(tokens)


def cost_normalized_bridging_efficiency(
    baseline_score: float,
    bridged_score: float,
    translation_tokens: float,
) -> float:
    improvement = bridged_score - baseline_score
    if translation_tokens <= 0:
        return 0.0
    return improvement / translation_tokens

<pipeline.py>
from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Protocol, Sequence, Callable

from .prompting import PromptBuilder
from .retrieval import HybridRetriever
from .selection import TranslationCandidate, TranslationSelector
from .translation import (
    SimpleSentenceSplitter,
    SentenceSplitter,
    Translator,
    estimate_alignment_quality,
    greedy_sentence_alignment,
)
from .types import EvidenceBlock, Query, RetrievalCandidate, TranslationRequest

PivotFn = Callable[[Sequence[RetrievalCandidate], str], str]


class Generator(Protocol):
    def generate(self, prompt: str) -> str:
        ...


@dataclass
class WeightingConfig:
    beta_search: float = 0.6
    beta_alignment: float = 0.2
    beta_slots: float = 0.2

    def normalize(self) -> "WeightingConfig":
        total = self.beta_search + self.beta_alignment + self.beta_slots
        if total == 0:
            return WeightingConfig(1.0, 0.0, 0.0)
        return WeightingConfig(
            beta_search=self.beta_search / total,
            beta_alignment=self.beta_alignment / total,
            beta_slots=self.beta_slots / total,
        )


@dataclass(frozen=True)
class PipelineOutput:
    answer: str
    evidence: Sequence[EvidenceBlock]
    prompt: str


def default_pivot(cands: Sequence[RetrievalCandidate], lq: str, tau: float = 0.6) -> str:
    total = max(len(cands), 1)
    lq_ratio = sum(1 for c in cands if c.segment.language == lq) / total
    return lq if lq_ratio >= tau else "en"


class LBRAGPipeline:
    def __init__(
        self,
        retriever: HybridRetriever,
        retriever_alpha: float | None,
        translator: Translator,
        generator: Generator,
        prompt_builder: PromptBuilder,
        translation_selector: TranslationSelector,
        weighting: WeightingConfig = WeightingConfig(),
        sentence_splitter: Optional[SentenceSplitter] = None,
        pivot_selector: PivotFn = default_pivot,
    ) -> None:
        self._retriever = retriever
        self._alpha = retriever_alpha if retriever_alpha is not None else retriever._config.alpha
        self._translator = translator
        self._generator = generator
        self._prompt_builder = prompt_builder
        self._selector = translation_selector
        self._weighting = weighting.normalize()
        self._splitter = sentence_splitter or SimpleSentenceSplitter()
        self._pivot_selector = pivot_selector

    def run(self, query: Query) -> PipelineOutput:
        candidates = self._retriever.retrieve(query)
        self._pivot = self._pivot_selector(candidates, query.language)
        plan = self._selector.select(self._to_translation_candidates(candidates))
        evidence_blocks = self._build_evidence_blocks(query, candidates, plan.selected)
        prompt = self._prompt_builder.build(query.text, evidence_blocks, query.language)
        answer = self._generator.generate(prompt)
        return PipelineOutput(answer=answer, evidence=evidence_blocks, prompt=prompt)

    def _to_translation_candidates(
        self, candidates: Sequence[RetrievalCandidate]
    ) -> Sequence[TranslationCandidate]:
        translated_candidates = []
        for candidate in candidates:
            metadata = candidate.segment.metadata
            confidence = float(metadata.get("translation_confidence", 1.0))
            cost = float(metadata.get("translation_cost", self._estimate_cost(candidate.segment.text)))
            translated_candidates.append(
                TranslationCandidate(
                    segment=candidate.segment,
                    relevance=candidate.final_score(alpha=self._alpha),
                    confidence=max(0.0, min(1.0, confidence)),
                    cost=max(cost, 1.0),
                )
            )
        return tuple(translated_candidates)

    def _estimate_cost(self, text: str) -> float:
        tokens = max(len(text) // 3, 1)
        return float(tokens)

    def _build_evidence_blocks(
        self,
        query: Query,
        candidates: Sequence[RetrievalCandidate],
        selected: Sequence[TranslationCandidate],
    ) -> Sequence[EvidenceBlock]:
        selected_ids = {candidate.segment.identifier for candidate in selected}
        blocks = []
        for candidate in candidates:
            if candidate.segment.identifier in selected_ids:
                block = self._translate_and_align(candidate)
            else:
                block = self._build_untranslated_block(candidate)
            blocks.append(block)
        blocks.sort(key=lambda b: b.weight, reverse=True)
        return tuple(blocks)

    def _translate_and_align(self, candidate: RetrievalCandidate) -> EvidenceBlock:
        segment = candidate.segment
        request = TranslationRequest(segment=segment, target_language=self._pivot)
        result = self._translator.translate(request)
        source_sentences = self._splitter.split(segment.text)
        alignments = greedy_sentence_alignment(source_sentences, result.sentences)
        coverage, slots = estimate_alignment_quality(alignments, len(source_sentences))
        weight = self._compute_weight(candidate, coverage, slots)
        metadata = {"translation_confidence": result.confidence}
        return EvidenceBlock(
            segment=segment,
            translated_text=result.translated_text,
            alignment=alignments,
            weight=weight,
            metadata=metadata,
        )

    def _build_untranslated_block(self, candidate: RetrievalCandidate) -> EvidenceBlock:
        weight = self._compute_weight(candidate, 0.0, 0.0)
        return EvidenceBlock(
            segment=candidate.segment,
            translated_text=None,
            alignment=tuple(),
            weight=weight,
            metadata={"translation_confidence": 0.0},
        )

    def _compute_weight(self, candidate: RetrievalCandidate, coverage: float, slots: float) -> float:
        w = self._weighting
        score = candidate.final_score(alpha=self._alpha)
        return w.beta_search * score + w.beta_alignment * coverage + w.beta_slots * slots

<prompting.py>
from __future__ import annotations

from dataclasses import dataclass
from typing import Iterable, Sequence

from .types import EvidenceBlock


MAX_EVID_CHARS = 800

@dataclass(frozen=True)
class PromptTemplate:
    system_instruction: str
    citation_instruction: str
    answer_instruction: str


class PromptBuilder:
    def __init__(self, template: PromptTemplate) -> None:
        self._template = template

    def build(self, question: str, evidence: Sequence[EvidenceBlock], target_language: str) -> str:
        header = self._template.system_instruction.format(language=target_language)
        citation = self._template.citation_instruction
        body = self._render_evidence(evidence)
        answer = self._template.answer_instruction.format(language=target_language)
        return "\n\n".join([header, f"Question: {question}", body, citation, answer])

    def _render_evidence(self, evidence: Sequence[EvidenceBlock]) -> str:
        lines = ["Evidence (ranked):"]
        for block in evidence:
            base = f"[{block.segment.identifier}] ({block.segment.language})"
            text = (block.translated_text or block.segment.text).strip()
            if len(text) > MAX_EVID_CHARS:
                text = text[:MAX_EVID_CHARS] + " ...[truncated]"
            lines.append(f"- {base}: {text}")
        return "\n".join(lines)

<retrieval.py>
from __future__ import annotations

from dataclasses import dataclass
from typing import List, Mapping, MutableMapping, Optional, Protocol, Sequence

from .types import DocumentSegment, Query, RetrievalCandidate


class Retriever(Protocol):
    def retrieve(self, query: Query, top_k: int) -> Sequence[RetrievalCandidate]:
        ...


class Reranker(Protocol):
    def score(self, query: Query, candidates: Sequence[DocumentSegment]) -> Sequence[float]:
        ...


@dataclass
class RetrievalConfig:
    alpha: float = 0.5
    top_k: int = 20


class HybridRetriever:
    def __init__(
        self,
        retrievers: Mapping[str, Retriever],
        reranker: Optional[Reranker] = None,
        config: RetrievalConfig = RetrievalConfig(),
    ) -> None:
        self._retrievers = dict(retrievers)
        self._reranker = reranker
        self._config = config

    def retrieve(self, query: Query) -> Sequence[RetrievalCandidate]:
        merged = self._collect_candidates(query)
        ranked = self._apply_reranker(query, merged)
        ranked.sort(key=lambda c: c[1], reverse=True)
        top = [cand for cand, _ in ranked[: self._config.top_k]]
        return top

    def _collect_candidates(
        self, query: Query
    ) -> MutableMapping[str, RetrievalCandidate]:
        merged: MutableMapping[str, RetrievalCandidate] = {}
        for language, retriever in self._retrievers.items():
            _ = language  # explicit unused binding to keep order intention clear
            for candidate in retriever.retrieve(query, self._config.top_k):
                existing = merged.get(candidate.segment.identifier)
                if existing is None or candidate.dense_score > existing.dense_score:
                    merged[candidate.segment.identifier] = candidate
        return merged

    def _apply_reranker(
        self,
        query: Query,
        merged: Mapping[str, RetrievalCandidate],
    ) -> List[tuple[RetrievalCandidate, float]]:
        if not merged:
            return []
        candidates = list(merged.values())
        if self._reranker is None:
            return [(c, c.final_score(self._config.alpha)) for c in candidates]
        segments = [c.segment for c in candidates]
        rerank_scores = self._reranker.score(query, segments)
        augmented: List[tuple[RetrievalCandidate, float]] = []
        for candidate, rerank_score in zip(candidates, rerank_scores):
            enriched = RetrievalCandidate(
                segment=candidate.segment,
                dense_score=candidate.dense_score,
                rerank_score=rerank_score,
            )
            augmented.append((enriched, enriched.final_score(self._config.alpha)))
        return augmented

<selection.py>
from __future__ import annotations

from dataclasses import dataclass
from typing import Iterable, List, Sequence

from .types import DocumentSegment


@dataclass(frozen=True)
class TranslationCandidate:
    segment: DocumentSegment
    relevance: float
    confidence: float
    cost: float

    @property
    def efficiency(self) -> float:
        if self.cost <= 0:
            return float("inf")
        return (self.relevance * self.confidence) / self.cost


@dataclass(frozen=True)
class TranslationPlan:
    selected: Sequence[TranslationCandidate]
    skipped: Sequence[TranslationCandidate]
    budget: float
    spent: float


class TranslationSelector:
    def __init__(self, budget: float, min_efficiency: float = 1e-6) -> None:
        self._budget = max(0.0, budget)
        self._min_eff = min_efficiency

    def select(self, candidates: Iterable[TranslationCandidate]) -> TranslationPlan:
        pool = sorted(candidates, key=lambda c: c.efficiency, reverse=True)
        chosen, skipped, remaining = [], [], self._budget
        for c in pool:
            if c.efficiency < self._min_eff: 
                skipped.append(c); continue
            if c.cost <= remaining:
                chosen.append(c); remaining -= c.cost
            else:
                skipped.append(c)
        for c in sorted((x for x in skipped if x.cost <= remaining), key=lambda x: x.efficiency, reverse=True):
            chosen.append(c); remaining -= c.cost
        spent = self._budget - remaining
        return TranslationPlan(tuple(chosen), tuple([x for x in skipped if x not in chosen]), self._budget, spent)

<translation.py>
from __future__ import annotations

import re
from dataclasses import dataclass
from typing import Protocol, Sequence

from .types import SentenceAlignment, TranslationRequest, TranslationResult


class Translator(Protocol):
    def translate(self, request: TranslationRequest) -> TranslationResult:
        ...


class SentenceSplitter(Protocol):
    def split(self, text: str) -> Sequence[str]:
        ...


@dataclass
class SimpleSentenceSplitter:
    pattern: re.Pattern[str] = re.compile(r"(?<=[.!?。！？])\s+")

    def split(self, text: str) -> Sequence[str]:
        parts = [t.strip() for t in self.pattern.split(text) if t.strip()]
        if not parts:
            return (text.strip(),) if text.strip() else tuple()
        return tuple(parts)

@dataclass
class RegexSentenceSplitter:
    pattern: re.Pattern[str] = re.compile(r"(?<=[。．！？!?]|[.!?])")

    def split(self, text: str) -> Sequence[str]:
        parts = [t.strip() for t in self.pattern.split(text) if t.strip()]
        return tuple(parts) if parts else ((text.strip(),) if text.strip() else tuple())


def greedy_sentence_alignment(
    source_sentences: Sequence[str],
    target_sentences: Sequence[str],
) -> Sequence[SentenceAlignment]:
    if not source_sentences or not target_sentences:
        return tuple()
    alignments: list[SentenceAlignment] = []
    target_iter = iter(target_sentences)
    current_target = next(target_iter, None)
    for source in source_sentences:
        if current_target is None:
            break
        alignments.append(
            SentenceAlignment(
                source_sentence=source,
                target_sentence=current_target,
                slot_matches=_extract_slot_matches(source, current_target),
            )
        )
        current_target = next(target_iter, None)
    return tuple(alignments)


def _extract_slot_matches(source: str, target: str) -> dict[str, Sequence[str]]:
    slots: dict[str, Sequence[str]] = {}
    patterns = {
        "numbers": re.findall(r"[-+]?[0-9]+(?:[.,][0-9]+)?", source),
        "dates": re.findall(r"\b\d{4}[-/.]\d{1,2}[-/.]\d{1,2}\b", source),
        "upper": re.findall(r"\b[A-Z][A-Za-z0-9_-]+\b", source),
    }
    for key, values in patterns.items():
        if values:
            target_values = []
            for value in values:
                if value in target:
                    target_values.append(value)
            slots[key] = tuple(target_values)
    return slots


def estimate_alignment_quality(alignments: Sequence[SentenceAlignment], total_sentences: int) -> tuple[float, float]:
    if total_sentences == 0:
        return 0.0, 0.0
    coverage = len(alignments) / total_sentences
    if not alignments:
        return coverage, 0.0
    match_hits = 0
    match_total = 0
    for alignment in alignments:
        for values in alignment.slot_matches.values():
            match_total += 1
            if values:
                match_hits += 1
    consistency = match_hits / match_total if match_total else 1.0
    return coverage, consistency

<types.py>
from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any, Dict, Optional, Sequence


@dataclass(frozen=True)
class Query:
    text: str
    language: str
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass(frozen=True)
class DocumentSegment:
    identifier: str
    text: str
    language: str
    score: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)

    def with_score(self, score: float) -> "DocumentSegment":
        return DocumentSegment(
            identifier=self.identifier,
            text=self.text,
            language=self.language,
            score=score,
            metadata=self.metadata,
        )


@dataclass(frozen=True)
class RetrievalCandidate:
    segment: DocumentSegment
    dense_score: float
    rerank_score: Optional[float]

    def final_score(self, alpha: float) -> float:
        if self.rerank_score is None:
            return self.dense_score
        return alpha * self.dense_score + (1 - alpha) * self.rerank_score


@dataclass(frozen=True)
class TranslationRequest:
    segment: DocumentSegment
    target_language: str


@dataclass(frozen=True)
class TranslationResult:
    translated_text: str
    confidence: float
    sentences: Sequence[str]
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass(frozen=True)
class SentenceAlignment:
    source_sentence: str
    target_sentence: str
    slot_matches: Dict[str, Sequence[str]]


@dataclass(frozen=True)
class EvidenceBlock:
    segment: DocumentSegment
    translated_text: Optional[str]
    alignment: Sequence[SentenceAlignment]
    weight: float
    metadata: Dict[str, Any] = field(default_factory=dict)
